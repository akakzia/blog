<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>When Graph Neural Networks Meet Reinforcement Learning</title>
  <meta name="description" content="An overview on Graph Neural Networks in Reinforcement Learning.">
  <link rel="canonical" href="http://localhost:4000/graph-neural-networks">
  <link rel="alternate" type="application/rss+xml" title="Ahmed Akakzia Feed"
    href="http://localhost:4000/feed.xml">
  
  <link rel="shortcut icon" href="/images/tabicon.png" type="image/png" />
  
  <!-- Styles -->
  <link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i%7CNoto+Serif:400,400i,700,700i&display=swap" rel="stylesheet">
  <link href="/assets/css/style.css" rel="stylesheet">
</head>
<body>

  <div id="page" class="site">
    <div class="inner">
      <header class="site-header">
  
  <p class="site-title"><a class="logo-text" href="/">Ahmed Akakzia</a></p>
  
  <nav class="site-navigation">
    <div class="site-navigation-wrap">
      <h2 class="screen-reader-text">Main navigation</h2>
      <ul class="menu">
        
        
        
        <li class="menu-item ">
          <a class="" href="/">Home</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/about/">About</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/publications/">Publications</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/scientific/">Science Lab</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/style-guide/">Style Guide</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/contact/">Contact</a>
        </li>
        
      </ul><!-- .menu -->
      <button id="menu-close" class="menu-toggle"><span class="screen-reader-text">Close Menu</span><span
          class="icon-close" aria-hidden="true"></span></button>
    </div><!-- .site-navigation-wrap -->
  </nav><!-- .site-navigation -->
  <button id="menu-open" class="menu-toggle"><span class="screen-reader-text">Open Menu</span><span class="icon-menu" aria-hidden="true"></span></button>
</header>


      <main class="main-content fadeInDown delay_075s">

  <article class="post">
    <header class="post-header">
      <time class="post-date" datetime="2022-09-25">September 25, 2022</time>
      <h1 class="post-title">When Graph Neural Networks Meet Reinforcement Learning</h1>
      <div class="post-meta">
        By <span class="post-author">Ahmed Akakzia</span>
      </div><!-- .post-meta -->
      
      <figure class="post-thumbnail image-card width-wide">
        <img src="/images/graphs.png" alt="When Graph Neural Networks Meet Reinforcement Learning">
      </figure><!-- .post-thumbnail -->
      
    </header><!-- .post-header -->
    <div class="post-content">
      <blockquote>
  <p>Reinforcement Learning (RL) agents should be able to efficiently generalize to novel situations and transfer their learned skills. Without these properties, such agents would always have to learn from scratch, even though they have already mastered primitive skills that could potentially be leveraged to acquire more complex ones.</p>
</blockquote>

<!--more-->

<p>Combining primitive skills and building upon them to solve harder tasks is a key challenge within artificial intelligence. In the context of <em>goal-conditioned agents</em>, transfer and adaptibility seem to depend on two key features: <em>the goal space design</em>, and <em>the policy architecture</em>. On the one hand, the goal representation—whether it is learned or predefined—should encapsulate an adequate structure that defines a specific topology in the goal space.</p>

<p>On the other hand, since the behavior of artificial agents does not only depend on how they represent their goals, but also on how they take actions, we investigate <em>Graph Neural Networks</em> (GNNs) as technical tools to model policies in autotelic agents. This choice is also motivated by developmental approaches, as research in psychology shows that humans perceive their world in a structured fashion <a class="citation" href="#winston1970learning"> [1,2,3,4,5,6,7,8,9]</a>.</p>

<p>This blog post is organized as follows. First, we start by introducing GNNs as technical tools to endow artificial agents with relational inductive biases. Then, we present an overview on the use of GNNs in the field of RL. Finally, we highlight several limitations of such combination.</p>

<h2 id="graph-neural-networks">Graph Neural Networks</h2>

<p>Recently, deep learning methods have been used to solve a significant amount of problems in different domains. Ranging from image classification <a class="citation" href="#redmon2016you"> [10,11]</a> and video processing <a class="citation" href="#zhang2016deep"> [12]</a> to speech recognition <a class="citation" href="#hinton2012deep"> [13]</a> and neural machine translation <a class="citation" href="#luong2015effective"> [14,15]</a>, these methods use parameterized neural networks as building blocks. Consequently, such methods are usually end-to-end, requiring few to no assumptions. They feed their networks with raw streams of data which are usually represented in the Euclidean Space. However, many applications rather represent data in non-Euclidean domains and use graphs with complex relationships and inter-dependencies. Standard usage of deep learning techniques usually struggle with this type of unstructured representations.</p>

<p>Interestingly, research has been interested in leveraging graph-based information using neural networks. Namely, <em>Graph Neural Networks</em> (GNNs) were proposed as computational frameworks that handle unstructured data using neural networks that they share between nodes and edges <a class="citation" href="#wang2016learning"> [16,7,17,18,19,20,8,21,22,23,24,25,26,27]</a>. Although these methods are all based on the same idea, they use different techniques depending on how they handle computations within their GNNs’ definition. There exist several surveys that propose different taxonomies for GNNs-based methods <a class="citation" href="#bronstein2017geometric"> [28,29,8,30,31]</a>. In this section, rather than presenting an exhaustive survey of GNNs, our goal is to define the building blocks including definitions and computational schemes. Besides, we focus on applications in RL and present a short overview of standard methods.</p>

<h3 id="relational-inductive-bias-with-graph-neural-networks">Relational Inductive Bias with Graph Neural Networks</h3>

<p>First, we propose a definition for the central component of GNNs: the graph.</p>

<p><strong>Graph.</strong> A graph is a mathematical structure used to model <em>pairwise relations</em> between <em>objects</em>. More formally, we denote a graph by an ordered pair \(G=(V, E)\), where \(V\) is the set of vertices or nodes—the objects—and \(E\) is the set of edges—the pairwise relations. We denote a single node by \(v_i \in V\), and an edge traveling from node \(v_i\) to node \(v_j\) as \(e_{ij} \in E\). We also define the neighborhood of a node \(v_i\) to be the set of nodes to which \(v_i\) is connected by an edge. Formally, this set is defined as</p>

\[\mathcal{N}(v_i) = \{v_j \in V~|~e_{ij} \in E\}.\]

<p>Finally, we consider some global features which characterize the whole graph, and we denote them by \(u\).</p>

<p><strong>Undirected and Directed Graphs.</strong> The definition above suggests that the edges of a graph \(G\) are inherently directed from a <em>source</em> node to a <em>recipient</em> node. In some special scenarios, a graph can be <em>undirected</em>: that is, \(e_{ij} = e_{ji}\) for each pair of nodes \(v_i\) and \(v_j\). In this case, the relation between nodes is said to be <em>symmetric</em>. If the edges are distinguished from their inverted counterparts (\(e_{ij} \neq e_{ji}\)), then the graph is said to be <em>directed</em>.</p>

<h4 id="graph-input">Graph Input</h4>

<p>The input of a graph corresponds to the parsed input features of all its nodes, all its edges and some other global features characterizing the whole system. Active lines of research that are orthogonal to our work are exploring methods that enable the extraction of such parsed features from raw sensory data <a class="citation" href="#watters2017visual"> [32,33,34,35]</a>. To simplify our study, we suppose the existence of a <em>predefined feature extractor</em> that automatically generates input values for each node and edge. For simplicity, we respectively denote the input features of node \(i\), edge \(i \rightarrow j\) and global features by \(v_i\), \(e_{ij}\) and \(u\).</p>

<h4 id="graph-output">Graph Output</h4>

<p>Depending on the graph structure and the task at hand, the output of the graph can focus on different graph levels. If the functions used to produce this output are modeled by neural networks, then we speak about GNNs.</p>

<p><strong>Node-level.</strong> This level focuses on the nodes of the graph. In this scenario, input features including node, edge and global features are used to produce a new embedding for each node. This can be used to perform regression and classification at the level of nodes and learn about the physical dynamics of each object <a class="citation" href="#battaglia2016interaction"> [7,36,22,20]</a>.</p>

<p><strong>Edge-level.</strong> This level focuses on the edges of the graph. The output of the computational scheme in this case are the updated features of each node after propagating the information between all the nodes. For instance, it can be used to make decisions about interactions among the different objects <a class="citation" href="#kipf2018neural"> [35,37]</a>.</p>

<p><strong>Graph-level.</strong> This level focuses on the entire graph. The output corresponds to a global embedding computed after propagating the information between all nodes of the graph. It can be used by embodied agents to produce actions in multi-object scenarios <a class="citation" href="#akakzia2021grounding"> [26,27]</a>, to answer questions about a visual scene <a class="citation" href="#santoro2017simple"> [17]</a> or to extract the global properties molecules in chemistry <a class="citation" href="#gilmer2017neural"> [38]</a>.</p>

<h4 id="graph-computation">Graph Computation</h4>

<p>So far, we have formally defined graphs and distinguished three types of attention-levels which define their output. Thereafter, we explain how exactly the computation of this output is conducted. The computational scheme within GNNs involves two main properties. First, it is based on <em>shared</em> neural networks which are used to compute the updated features of all the nodes and edges. Second, it uses <em>aggregation functions</em> that pool these features in order to produce the output. These two properties provide GNNs with good combinatorial generalization capabilities. In fact, not only it enables good transfer between different nodes and edges (based on the shared networks), but also it leverages permutation invariance (based on the aggregation scheme).</p>

<p>We denote the shared neural networks between the nodes by \(NN_{nodes}\), the shared neural networks between edges by \(NN_{edges}\), and the readout neural network that produces the global output of the GNN by \(NN_{readout}\). Besides, we focus on <em>graph-level output</em>. The full computational scheme is based on three steps: the <em>edge updates</em>, the <em>node updates</em> and the <em>graph readout</em>.</p>

<p><strong>The edge update step.</strong> The edge update step consists in using the input features involving each edge \(i \rightarrow j\) to compute its updated features, which we note \(e'_{ij}\). More precisely, we consider the global input feature \(u\), the input features of the source node \(v_i\) and the input features of the recipient node \(v_j\). We use the shared network \(NN_{edges}\) to compute the updated features of all the edges. Formally, the updated features \(e'_{ij}\) of the edge \(i \rightarrow j\) are computed as follows:</p>

\[e'_{ij}~=~NN_{edges}(v_i, v_j, e_{ij}, u).\]

<p><strong>The node update step.</strong> The node update step aims at computing the updated features of all the nodes. We note \(v'_{i}\) these updated features for node \(i\). To do so, the input features of the underlying node, the global features as well as the aggregation of the updated features of the incoming edges to \(i\) are considered. The incoming edges to \(i\) correspond to edges whose source nodes are necessarily in the neighborhood of \(i\), \(\mathcal{N}(i)\). The shared network \(NN_{nodes}\) is used in this computation. Formally, the updated features \(v'_{i}\) of the node \(i\) are obtained as follows:</p>

\[v'_{i}~=~NN_{nodes}(v_i, Agg_{i \in \mathcal{N}(i)}(e'_{ij}), u).\]

<p><strong>The graph readout step.</strong> The graph readout step computes the global output of the graph. This quantity is obtained by aggregating all the updated features of the nodes within the graph. It uses the readout neural network \(NN_{readout}\). Formally, the output \(o\) of the GNN is computed as follows:</p>

\[o~=~NN_{readout}(Agg_{i \in graph}(v'_{i})).\]

<p>The computational steps we described above can be used in some other order. For example, one can first perform the node update using the input features of edges, then perform the edge updates using the updated nodes features. This choice usually depends on the domain and task at hand. Besides, our descriptions above are categorized within the family of <em>convolutional GNNs</em> <a class="citation" href="#bruna2013spectral"> [39,40,41,42,43,38,27]</a>, which generalize the operation of convolution from grid data to graph data by pooling features of neighbors when updating each node. There exist other categories of GNNs, such as <em>graph auto-encoders</em> <a class="citation" href="#cao2016deep"> [44,45,46,47,34]</a>, <em>spatio-temporal GNNs</em> <a class="citation" href="#yu2017spatio"> [48,49,50,51]</a> and <em>recurrent GNNs</em> <a class="citation" href="#scarselli2005graph"> [52,53,54,55]</a>. Finally, the aggregation module used to perform node-wise pooling can be either some predefined permutation-invariant function such as sum, max or mean, or a more sophisticated self-attention-based function that learns attention weights for each node <a class="citation" href="#velivckovic2017graph"> [56]</a>.</p>

<h3 id="overview-on-graph-neural-networks-in-rl">Overview on Graph Neural Networks in RL</h3>

<p>Recently, Graph Neural Networks have been widely used in Reinforcement Learning. In fact, they promote sample efficiency, especially in multi-object manipulation domains, where object invariance becomes crucial for generalization. In this paragraph, we introduce an overview over recent works in RL using GNNs. We divide the works in two categories: GNNs used for <em>model-based</em> RL and for <em>model-free</em> RL.</p>

<p><strong>Model-based Reinforcement Learning.</strong> The idea of using GNNs in model-based reinforcement learning settings mainly amounts to representing the perceived world of the artificial agents with graphs. Recent papers have been using GNNs to learn prediction models by construction graph representations using the bodies and joints of the agents <a class="citation" href="#wang2016learning"> [16,19,20]</a>. This approach is shown to be successful in prediction, system identification and planning. However, these approaches struggle when the structure of the components and joints of the agent are different. For example, they work better on the Swimmer environment than HalfCheetah, since the latter contains more joints corresponding to different components (back leg, front leg, head …). Other approaches use Interaction Networks <a class="citation" href="#battaglia2016interaction"> [7]</a>, which are a particular type of GNNs to implement transition models of the environment which they later use for imagination-based optimization <a class="citation" href="#hamrick2017metacontrol"> [19]</a> or planning from scratch <a class="citation" href="#wang2016learning"> [16]</a></p>

<p><strong>Model-free Reinforcement Learning.</strong> GNNs are also used in model-free reinforcement learning to model the policy and / or the value function <a class="citation" href="#wang2018nervenet"> [22,21,23,24,25,26]</a>. On the one hand, like the model-based setting, some approaches use them to represent the agent’s body and joints as a graph where the different components interact with each other to produce an action <a class="citation" href="#wang2018nervenet"> [22]</a>. On the other hand, other approaches use it to represent the world in term of separate entities and attempt to capture the relational features between them <a class="citation" href="#zambaldi2018relational"> [21,23,24,25,26]</a>.</p>

<h3 id="limitations">Limitations</h3>

<p>In spite of their generalization capacities provided by their permutation invariance, GNNs still show some limitations to solve some classes of problems such as discriminating between certain non-isomorphic graphs <a class="citation" href="#kondor2018generalization"> [57]</a>. Moreover, notions like recursion, control flow and conditional iteration are not straightforward to represent with graphs, and might require some domain-specific tweaks (for example, in interpreting abstract syntax trees). In fact, symbolic  programs using probabilistic models are shown to work better on these classes of problems <a class="citation" href="#tenenbaum2011grow"> [6,58,59]</a>. But more importantly, a more pressing question is about the origin of the graph networks that most of the methods work on. In fact, most approaches that use GNNs use graphs with predefined entities corresponding to structured objects. Removing this assumption, it is still unclear how to convert sensory data into more structured graph-like representations. Some lines of active research are exploring these issues <a class="citation" href="#watters2017visual"> [32,33,34,35]</a>.</p>

<!--- References -->

<ol class="bibliography"><li><span id="winston1970learning">[1]P. H. Winston, <i>Learning Structural Descriptions from Examples</i>, None (1970).</span></li>
<li><span id="palmer1975visual">[2]S. E. Palmer, <i>Visual Perception and World Knowledge: Notes on a Model of Sensory-Cognitive Interaction</i>, Explorations in Cognition 279 (1975).</span></li>
<li><span id="navon1977forest">[3]D. Navon, <i>Forest before Trees: The Precedence of Global Features in Visual Perception</i>, Cognitive Psychology <b>9</b>, 353 (1977).</span></li>
<li><span id="markman1989categorization">[4]E. M. Markman, <i>Categorization and Naming in Children: Problems of Induction</i> (mit Press, 1989).</span></li>
<li><span id="kemp2008discovery">[5]C. Kemp and J. B. Tenenbaum, <i>The Discovery of Structural Form</i>, Proceedings of the National Academy of Sciences <b>105</b>, 10687 (2008).</span></li>
<li><span id="tenenbaum2011grow">[6]J. B. Tenenbaum, C. Kemp, T. L. Griffiths, and N. D. Goodman, <i>How to Grow a Mind: Statistics, Structure, and Abstraction</i>, Science <b>331</b>, 1279 (2011).</span></li>
<li><span id="battaglia2016interaction">[7]P. Battaglia, R. Pascanu, M. Lai, D. Jimenez Rezende, and others, <i>Interaction Networks for Learning about Objects, Relations and Physics</i>, Advances in Neural Information Processing Systems <b>29</b>, (2016).</span></li>
<li><span id="battaglia2018relational">[8]P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner, and others, <i>Relational Inductive Biases, Deep Learning, and Graph Networks</i>, ArXiv Preprint ArXiv:1806.01261 (2018).</span></li>
<li><span id="godfrey2021theory">[9]P. Godfrey-Smith, <i>Theory and Reality</i>, in <i>Theory and Reality</i> (University of Chicago Press, 2021).</span></li>
<li><span id="redmon2016you">[10]J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, <i>You Only Look Once: Unified, Real-Time Object Detection</i>, in <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i> (2016), pp. 779–788.</span></li>
<li><span id="ren2015faster">[11]S. Ren, K. He, R. Girshick, and J. Sun, <i>Faster r-Cnn: Towards Real-Time Object Detection with Region Proposal Networks</i>, Advances in Neural Information Processing Systems <b>28</b>, (2015).</span></li>
<li><span id="zhang2016deep">[12]W. Zhang, L. Xu, Z. Li, Q. Lu, and Y. Liu, <i>A Deep-Intelligence Framework for Online Video Processing</i>, IEEE Software <b>33</b>, 44 (2016).</span></li>
<li><span id="hinton2012deep">[13]G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-rahman Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, and others, <i>Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups</i>, IEEE Signal Processing Magazine <b>29</b>, 82 (2012).</span></li>
<li><span id="luong2015effective">[14]M.-T. Luong, H. Pham, and C. D. Manning, <i>Effective Approaches to Attention-Based Neural Machine Translation</i>, ArXiv Preprint ArXiv:1508.04025 (2015).</span></li>
<li><span id="wu2017sequence">[15]S. Wu, D. Zhang, N. Yang, M. Li, and M. Zhou, <i>Sequence-to-Dependency Neural Machine Translation</i>, in <i>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i> (2017), pp. 698–707.</span></li>
<li><span id="wang2016learning">[16]J. X. Wang, Z. Kurth-Nelson, D. Tirumala, H. Soyer, J. Z. Leibo, R. Munos, C. Blundell, D. Kumaran, and M. Botvinick, <i>Learning to Reinforcement Learn</i>, ArXiv Preprint ArXiv:1611.05763 (2016).</span></li>
<li><span id="santoro2017simple">[17]A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia, and T. Lillicrap, <i>A Simple Neural Network Module for Relational Reasoning</i>, Advances in Neural Information Processing Systems <b>30</b>, (2017).</span></li>
<li><span id="zaheer2017deep">[18]M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola, <i>Deep Sets</i>, in <i>Advances in Neural Information Processing Systems</i> (2017), pp. 3391–3401.</span></li>
<li><span id="hamrick2017metacontrol">[19]J. B. Hamrick, A. J. Ballard, R. Pascanu, O. Vinyals, N. Heess, and P. W. Battaglia, <i>Metacontrol for Adaptive Imagination-Based Optimization</i>, ArXiv Preprint ArXiv:1705.02670 (2017).</span></li>
<li><span id="sanchez2018graph">[20]A. Sanchez-Gonzalez, N. Heess, J. T. Springenberg, J. Merel, M. Riedmiller, R. Hadsell, and P. Battaglia, <i>Graph Networks as Learnable Physics Engines for Inference and Control</i>, in <i>International Conference on Machine Learning</i> (PMLR, 2018), pp. 4470–4479.</span></li>
<li><span id="zambaldi2018relational">[21]V. Zambaldi, D. Raposo, A. Santoro, V. Bapst, Y. Li, I. Babuschkin, K. Tuyls, D. Reichert, T. Lillicrap, E. Lockhart, and others, <i>Relational Deep Reinforcement Learning</i>, ArXiv Preprint ArXiv:1806.01830 (2018).</span></li>
<li><span id="wang2018nervenet">[22]T. Wang, R. Liao, J. Ba, and S. Fidler, <i>NerveNet: Learning Structured Policy with Graph Neural Networks</i>, in <i>International Conference on Learning Representations</i> (2018).</span></li>
<li><span id="bapst2019structured">[23]V. Bapst, A. Sanchez-Gonzalez, C. Doersch, K. Stachenfeld, P. Kohli, P. Battaglia, and J. B. Hamrick, <i>Structured Agents for Physical Construction</i>, in <i>International Conference on Machine Learning</i> (PMLR, 2019), pp. 464–474.</span></li>
<li><span id="li2019towards">[24]R. Li, A. Jabri, T. Darrell, and P. Agrawal, <i>Towards Practical Multi-Object Manipulation Using Relational Reinforcement Learning</i>, ArXiv Preprint <b>abs/1912.11032</b>, (2019).</span></li>
<li><span id="colas2020language">[25]C. Colas, T. Karch, N. Lair, J.-M. Dussoux, C. Moulin-Frier, P. F. Dominey, and P.-Y. Oudeyer, <i>Language as a Cognitive Tool to Imagine Goals in Curiosity Driven
Exploration</i>, in <i>Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, Virtual</i>, edited by H. Larochelle, M. A. Ranzato, R. Hadsell, M.-F. Balcan, and H.-T. Lin (2020).</span></li>
<li><span id="akakzia2021grounding">[26]A. Akakzia, C. Colas, P.-Y. Oudeyer, M. Chetouani, and O. Sigaud, <i>Grounding Language to Autonomously-Acquired Skills via Goal Generation</i>, in <i>9th International Conference on Learning Representations, ICLR 2021,
Virtual Event, Austria, May 3-7, 2021</i> (OpenReview.net, 2021).</span></li>
<li><span id="akakzia2022learning">[27]A. Akakzia and O. Sigaud, <i>Learning Object-Centered Autotelic Behaviors with Graph Neural Networks</i>, ArXiv Preprint ArXiv:2204.05141 (2022).</span></li>
<li><span id="bronstein2017geometric">[28]M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst, <i>Geometric Deep Learning: Going beyond Euclidean Data</i>, IEEE Signal Processing Magazine <b>34</b>, 18 (2017).</span></li>
<li><span id="hamilton2017representation">[29]W. L. Hamilton, R. Ying, and J. Leskovec, <i>Representation Learning on Graphs: Methods and Applications</i>, ArXiv Preprint ArXiv:1709.05584 (2017).</span></li>
<li><span id="lee2018graph">[30]J. B. Lee, R. Rossi, and X. Kong, <i>Graph Classification Using Structural Attention</i>, in <i>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</i> (2018), pp. 1666–1674.</span></li>
<li><span id="wu2020comprehensive">[31]Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, <i>A Comprehensive Survey on Graph Neural Networks</i>, IEEE Transactions on Neural Networks and Learning Systems <b>32</b>, 4 (2020).</span></li>
<li><span id="watters2017visual">[32]N. Watters, D. Zoran, T. Weber, P. Battaglia, R. Pascanu, and A. Tacchetti, <i>Visual Interaction Networks: Learning a Physics Simulator from Video</i>, Advances in Neural Information Processing Systems <b>30</b>, (2017).</span></li>
<li><span id="van2018relational">[33]S. Van Steenkiste, M. Chang, K. Greff, and J. Schmidhuber, <i>Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and Their Interactions</i>, ArXiv Preprint ArXiv:1802.10353 (2018).</span></li>
<li><span id="li2018learning">[34]Y. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia, <i>Learning Deep Generative Models of Graphs</i>, ArXiv Preprint ArXiv:1803.03324 (2018).</span></li>
<li><span id="kipf2018neural">[35]T. Kipf, E. Fetaya, K.-C. Wang, M. Welling, and R. Zemel, <i>Neural Relational Inference for Interacting Systems</i>, in <i>International Conference on Machine Learning</i> (PMLR, 2018), pp. 2688–2697.</span></li>
<li><span id="chang2016compositional">[36]M. B. Chang, T. Ullman, A. Torralba, and J. B. Tenenbaum, <i>A Compositional Object-Based Approach to Learning Physical Dynamics</i>, ArXiv Preprint ArXiv:1612.00341 (2016).</span></li>
<li><span id="hamrick2018relational">[37]J. B. Hamrick, K. R. Allen, V. Bapst, T. Zhu, K. R. McKee, J. B. Tenenbaum, and P. W. Battaglia, <i>Relational Inductive Bias for Physical Construction in Humans and Machines</i>, ArXiv Preprint <b>abs/1806.01203</b>, (2018).</span></li>
<li><span id="gilmer2017neural">[38]J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl, <i>Neural Message Passing for Quantum Chemistry</i>, ArXiv Preprint ArXiv:1704.01212 (2017).</span></li>
<li><span id="bruna2013spectral">[39]J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, <i>Spectral Networks and Locally Connected Networks on Graphs</i>, ArXiv Preprint ArXiv:1312.6203 (2013).</span></li>
<li><span id="henaff2015deep">[40]M. Henaff, J. Bruna, and Y. LeCun, <i>Deep Convolutional Networks on Graph-Structured Data</i>, ArXiv Preprint ArXiv:1506.05163 (2015).</span></li>
<li><span id="defferrard2016convolutional">[41]M. Defferrard, X. Bresson, and P. Vandergheynst, <i>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</i>, Advances in Neural Information Processing Systems <b>29</b>, (2016).</span></li>
<li><span id="kipf2016semi">[42]T. N. Kipf and M. Welling, <i>Semi-Supervised Classification with Graph Convolutional Networks</i>, ArXiv Preprint ArXiv:1609.02907 (2016).</span></li>
<li><span id="levie2018cayleynets">[43]R. Levie, F. Monti, X. Bresson, and M. M. Bronstein, <i>Cayleynets: Graph Convolutional Neural Networks with Complex Rational Spectral Filters</i>, IEEE Transactions on Signal Processing <b>67</b>, 97 (2018).</span></li>
<li><span id="cao2016deep">[44]S. Cao, W. Lu, and Q. Xu, <i>Deep Neural Networks for Learning Graph Representations</i>, in <i>Proceedings of the AAAI Conference on Artificial Intelligence</i>, Vol. 30 (2016).</span></li>
<li><span id="wang2016structural">[45]D. Wang, P. Cui, and W. Zhu, <i>Structural Deep Network Embedding</i>, in <i>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i> (2016), pp. 1225–1234.</span></li>
<li><span id="kipf2016variational">[46]T. N. Kipf and M. Welling, <i>Variational Graph Auto-Encoders</i>, ArXiv Preprint ArXiv:1611.07308 (2016).</span></li>
<li><span id="pan2018adversarially">[47]S. Pan, R. Hu, G. Long, J. Jiang, L. Yao, and C. Zhang, <i>Adversarially Regularized Graph Autoencoder for Graph Embedding</i>, ArXiv Preprint ArXiv:1802.04407 (2018).</span></li>
<li><span id="yu2017spatio">[48]B. Yu, H. Yin, and Z. Zhu, <i>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting</i>, ArXiv Preprint ArXiv:1709.04875 (2017).</span></li>
<li><span id="li2017diffusion">[49]Y. Li, R. Yu, C. Shahabi, and Y. Liu, <i>Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</i>, ArXiv Preprint ArXiv:1707.01926 (2017).</span></li>
<li><span id="seo2018structured">[50]Y. Seo, M. Defferrard, P. Vandergheynst, and X. Bresson, <i>Structured Sequence Modeling with Graph Convolutional Recurrent Networks</i>, in <i>International Conference on Neural Information Processing</i> (Springer, 2018), pp. 362–373.</span></li>
<li><span id="guo2019attention">[51]S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan, <i>Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</i>, in <i>Proceedings of the AAAI Conference on Artificial Intelligence</i>, Vol. 33 (2019), pp. 922–929.</span></li>
<li><span id="scarselli2005graph">[52]F. Scarselli, S. L. Yong, M. Gori, M. Hagenbuchner, A. C. Tsoi, and M. Maggini, <i>Graph Neural Networks for Ranking Web Pages</i>, in <i>The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI’05)</i> (IEEE, 2005), pp. 666–672.</span></li>
<li><span id="gallicchio2010graph">[53]C. Gallicchio and A. Micheli, <i>Graph Echo State Networks</i>, in <i>The 2010 International Joint Conference on Neural Networks (IJCNN)</i> (IEEE, 2010), pp. 1–8.</span></li>
<li><span id="li2015gated">[54]Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, <i>Gated Graph Sequence Neural Networks</i>, ArXiv Preprint ArXiv:1511.05493 (2015).</span></li>
<li><span id="dai2018learning">[55]H. Dai, Z. Kozareva, B. Dai, A. Smola, and L. Song, <i>Learning Steady-States of Iterative Algorithms over Graphs</i>, in <i>International Conference on Machine Learning</i> (PMLR, 2018), pp. 1106–1114.</span></li>
<li><span id="velivckovic2017graph">[56]P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, <i>Graph Attention Networks</i>, ArXiv Preprint ArXiv:1710.10903 (2017).</span></li>
<li><span id="kondor2018generalization">[57]R. Kondor and S. Trivedi, <i>On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups</i>, in <i>International Conference on Machine Learning</i> (PMLR, 2018), pp. 2747–2755.</span></li>
<li><span id="goodman2014concepts">[58]N. D. Goodman, J. B. Tenenbaum, and T. Gerstenberg, Concepts in a Probabilistic Language of Thought, Center for Brains, Minds and Machines (CBMM), 2014.</span></li>
<li><span id="lake2015human">[59]B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum, <i>Human-Level Concept Learning through Probabilistic Program Induction</i>, Science <b>350</b>, 1332 (2015).</span></li></ol>

    </div><!-- .post-content -->
    <div class="post-share">
      <span>Share:</span>
      <a target="_blank"
        href="https://twitter.com/intent/tweet?text=When%20Graph%20Neural%20Networks%20Meet%20Reinforcement%20Learning&amp;url=http://localhost:4000/graph-neural-networks" rel="noopener">Twitter</a>
      <a target="_blank"
        href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/graph-neural-networks&amp;t=When%20Graph%20Neural%20Networks%20Meet%20Reinforcement%20Learning" rel="noopener">Facebook</a>
    </div><!-- .share-post -->
    <div class="author-box">
      
      <div class="author-avatar" style="background-image: url('images/author.png')"><span class="screen-reader-text">Ahmed Akakzia's Picture</span></div>
      
      <div class="author-details">
        <h2 class="author-title">About Ahmed Akakzia</h2>
        <div class="author-bio"><p>Ahmed is a final year PhD candidate, passionate about artificial intelligence</p>
</div>
        
        <span class="author-location">Paris, France</span>
        
        
      </div><!-- .author-details -->
    </div><!-- .author-box -->
  </article><!-- .post -->

  
    <div class="comments-area">
  <div class="comments-inner">
    <h2 class="comments-title">Comments</h2>
    <div id="disqus_thread"></div>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
        Disqus</a>.</noscript>
  </div><!-- .comments-inner -->
</div><!-- .comments-area -->

<script type="text/javascript">
  var disqus_shortname = 'justgoodthemes';
  var disqus_developer = 0;
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
  
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</main><!-- .main-content -->
      <footer class="site-footer">
  <div class="offsite-links">
    
      
<a href="https://twitter.com/aakakzia" target="_blank" rel="noopener">
  <span class="fa-twitter" aria-hidden="true"></span>
  <span class="screen-reader-text">Twitter</span>
</a>

<a href="https://github.com/akakzia" target="_blank" rel="noopener">
  <span class="fa-github" aria-hidden="true"></span>
  <span class="screen-reader-text">GitHub</span>
</a>

<a href="https://www.linkedin.com/in/ahmed-akakzia/" target="_blank" rel="noopener">
  <span class="fa-linkedin" aria-hidden="true"></span>
  <span class="screen-reader-text">LinkedIn</span>
</a>

    
  </div><!-- .offsite-links -->
  <div class="footer-bottom">
    <div class="site-info">
      <p>© 2022 Ahmed Akakzia. Theme customized from <a href="https://www.justgoodthemes.com">JustGoodThemes</a>.</p>

    </div><!-- .site-info -->
    <a href="#page" id="back-to-top" class="back-to-top"><span class="screen-reader-text">Back to the top </span>&#8593;</a>
  </div><!-- .footer-bottom -->
</footer><!-- .site-footer -->

    </div><!-- .inner -->
  </div><!-- .site -->

  <!-- Scripts -->
  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>
  
  <script src="/assets/js/plugins.js"></script>
  <script src="/assets/js/custom.js"></script>

</body>
</html>