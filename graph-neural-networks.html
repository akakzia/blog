<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>When Graph Neural Networks Meet Reinforcement Learning</title>
  <meta name="description" content="An overview on Graph Neural Networks in Reinforcement Learning.">
  <link rel="canonical" href="http://localhost:4000/blog/graph-neural-networks">
  <link rel="alternate" type="application/rss+xml" title="Ahmed Akakzia Feed"
    href="http://localhost:4000/blog/feed.xml">
  
  <link rel="shortcut icon" href="/blog/images/tabicon.png" type="image/png" />
  
  <!-- Styles -->
  <link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i%7CNoto+Serif:400,400i,700,700i&display=swap" rel="stylesheet">
  <link href="/blog/assets/css/style.css" rel="stylesheet">
</head>
<body>

  <div id="page" class="site">
    <div class="inner">
      <header class="site-header">
  
  <p class="site-title"><a class="logo-text" href="/blog/">Ahmed Akakzia</a></p>
  
  <nav class="site-navigation">
    <div class="site-navigation-wrap">
      <h2 class="screen-reader-text">Main navigation</h2>
      <ul class="menu">
        
        
        
        <li class="menu-item ">
          <a class="" href="/blog/index">Scientific Lab</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/blog/publications">Publications</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/blog/about">About</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/blog/contact">Contact</a>
        </li>
        
      </ul><!-- .menu -->
      <button id="menu-close" class="menu-toggle"><span class="screen-reader-text">Close Menu</span><span
          class="icon-close" aria-hidden="true"></span></button>
    </div><!-- .site-navigation-wrap -->
  </nav><!-- .site-navigation -->
  <button id="menu-open" class="menu-toggle"><span class="screen-reader-text">Open Menu</span><span class="icon-menu" aria-hidden="true"></span></button>
</header>


      <main class="main-content fadeInDown delay_075s">

  <article class="post">
    <header class="post-header">
      <time class="post-date" datetime="2022-09-25">September 25, 2022</time>
      <h1 class="post-title">When Graph Neural Networks Meet Reinforcement Learning</h1>
      <div class="post-meta">
        By <span class="post-author">Ahmed Akakzia</span>
      </div><!-- .post-meta -->
      
      <figure class="post-thumbnail image-card width-wide">
        <img src="/blog/images/graphs.png" alt="When Graph Neural Networks Meet Reinforcement Learning">
      </figure><!-- .post-thumbnail -->
      
    </header><!-- .post-header -->
    <div class="post-content">
      <blockquote>
  <p>Reinforcement Learning (RL) agents should be able to efficiently generalize to novel situations and transfer their learned skills. Without these properties, such agents would always have to learn from scratch, even though they have already mastered primitive skills that could potentially be leveraged to acquire more complex ones.</p>
</blockquote>

<!--more-->

<p>Combining primitive skills and building upon them to solve harder tasks is a key challenge within artificial intelligence. In the context of <em>goal-conditioned agents</em>, transfer and adaptibility seem to depend on two key features: <em>the goal space design</em>, and <em>the policy architecture</em>. On the one hand, the goal representation—whether it is learned or predefined—should encapsulate an adequate structure that defines a specific topology in the goal space.</p>

<p>On the other hand, since the behavior of artificial agents does not only depend on how they represent their goals, but also on how they take actions, we investigate <em>Graph Neural Networks</em> (GNNs) as technical tools to model policies in autotelic agents. This choice is also motivated by developmental approaches, as research in psychology shows that humans perceive their world in a structured fashion <a class="citation" href="#winston1970learning">[Winston 1970; Palmer 1975; Navon 1977; Markman 1989; Kemp and Tenenbaum 2008; Tenenbaum et al. 2011; Battaglia et al. 2016; Battaglia et al. 2018; Godfrey-Smith 2021]</a>.</p>

<p>This blog post is organized as follows. First, we start by introducing GNNs as technical tools to endow artificial agents with relational inductive biases. Then, we present an overview on the use of GNNs in the field of RL. Finally, we highlight several limitations of such combination.</p>

<h2 id="graph-neural-networks">Graph Neural Networks</h2>

<p>Recently, deep learning methods have been used to solve a significant amount of problems in different domains. Ranging from image classification <a class="citation" href="#redmon2016you">[Redmon et al. 2016; Ren et al. 2015]</a> and video processing <a class="citation" href="#zhang2016deep">[Zhang et al. 2016]</a> to speech recognition <a class="citation" href="#hinton2012deep">[Hinton et al. 2012]</a> and neural machine translation <a class="citation" href="#luong2015effective">[Luong et al. 2015; Wu et al. 2017]</a>, these methods use parameterized neural networks as building blocks. Consequently, such methods are usually end-to-end, requiring few to no assumptions. They feed their networks with raw streams of data which are usually represented in the Euclidean Space. However, many applications rather represent data in non-Euclidean domains and use graphs with complex relationships and inter-dependencies. Standard usage of deep learning techniques usually struggle with this type of unstructured representations.</p>

<p>Interestingly, research has been interested in leveraging graph-based information using neural networks. Namely, <em>Graph Neural Networks</em> (GNNs) were proposed as computational frameworks that handle unstructured data using neural networks that they share between nodes and edges <a class="citation" href="#wang2016learning">[Wang et al. 2016; Battaglia et al. 2016; Santoro et al. 2017; Zaheer et al. 2017; Hamrick et al. 2017; Sanchez-Gonzalez et al. 2018; Battaglia et al. 2018; Zambaldi et al. 2018; Wang et al. 2018; Bapst et al. 2019; Li et al. 2019; Colas et al. 2020; Akakzia et al. 2021; Akakzia and Sigaud 2022]</a>. Although these methods are all based on the same idea, they use different techniques depending on how they handle computations within their GNNs’ definition. There exist several surveys that propose different taxonomies for GNNs-based methods <a class="citation" href="#bronstein2017geometric">[Bronstein et al. 2017; Hamilton et al. 2017; Battaglia et al. 2018; Lee et al. 2018; Wu et al. 2020]</a>. In this blog post, rather than presenting an exhaustive survey of GNNs, our goal is to define the building blocks including definitions and computational schemes. Besides, we focus on applications in RL and present a short overview of standard methods.</p>

<h3 id="relational-inductive-bias-with-graph-neural-networks">Relational Inductive Bias with Graph Neural Networks</h3>

<p>First, we propose a definition for the central component of GNNs: the graph.</p>

<p><strong>Graph.</strong> A graph is a mathematical structure used to model <em>pairwise relations</em> between <em>objects</em>. More formally, we denote a graph by an ordered pair \(G=(V, E)\), where \(V\) is the set of vertices or nodes—the objects—and \(E\) is the set of edges—the pairwise relations. We denote a single node by \(v_i \in V\), and an edge traveling from node \(v_i\) to node \(v_j\) as \(e_{ij} \in E\). We also define the neighborhood of a node \(v_i\) to be the set of nodes to which \(v_i\) is connected by an edge. Formally, this set is defined as</p>

\[\mathcal{N}(v_i) = \{v_j \in V~|~e_{ij} \in E\}.\]

<p>Finally, we consider some global features which characterize the whole graph, and we denote them by \(u\).</p>

<p><strong>Undirected and Directed Graphs.</strong> The definition above suggests that the edges of a graph \(G\) are inherently directed from a <em>source</em> node to a <em>recipient</em> node. In some special scenarios, a graph can be <em>undirected</em>: that is, \(e_{ij} = e_{ji}\) for each pair of nodes \(v_i\) and \(v_j\). In this case, the relation between nodes is said to be <em>symmetric</em>. If the edges are distinguished from their inverted counterparts (\(e_{ij} \neq e_{ji}\)), then the graph is said to be <em>directed</em>.</p>

<h4 id="graph-input">Graph Input</h4>

<p>The input of a graph corresponds to the parsed input features of all its nodes, all its edges and some other global features characterizing the whole system. Active lines of research that are orthogonal to our work are exploring methods that enable the extraction of such parsed features from raw sensory data <a class="citation" href="#watters2017visual">[Watters et al. 2017; Van Steenkiste et al. 2018; Li et al. 2018; Kipf et al. 2018]</a>. To simplify our study, we suppose the existence of a <em>predefined feature extractor</em> that automatically generates input values for each node and edge. For simplicity, we respectively denote the input features of node \(i\), edge \(i \rightarrow j\) and global features by \(v_i\), \(e_{ij}\) and \(u\).</p>

<h4 id="graph-output">Graph Output</h4>

<p>Depending on the graph structure and the task at hand, the output of the graph can focus on different graph levels. If the functions used to produce this output are modeled by neural networks, then we speak about GNNs.</p>

<p><strong>Node-level.</strong> This level focuses on the nodes of the graph. In this scenario, input features including node, edge and global features are used to produce a new embedding for each node. This can be used to perform regression and classification at the level of nodes and learn about the physical dynamics of each object <a class="citation" href="#battaglia2016interaction">[Battaglia et al. 2016; Chang et al. 2016; Wang et al. 2018; Sanchez-Gonzalez et al. 2018]</a>.</p>

<p><strong>Edge-level.</strong> This level focuses on the edges of the graph. The output of the computational scheme in this case are the updated features of each node after propagating the information between all the nodes. For instance, it can be used to make decisions about interactions among the different objects <a class="citation" href="#kipf2018neural">[Kipf et al. 2018; Hamrick et al. 2018]</a>.</p>

<p><strong>Graph-level.</strong> This level focuses on the entire graph. The output corresponds to a global embedding computed after propagating the information between all nodes of the graph. It can be used by embodied agents to produce actions in multi-object scenarios <a class="citation" href="#akakzia2021grounding">[Akakzia et al. 2021; Akakzia and Sigaud 2022]</a>, to answer questions about a visual scene <a class="citation" href="#santoro2017simple">[Santoro et al. 2017]</a> or to extract the global properties molecules in chemistry <a class="citation" href="#gilmer2017neural">[Gilmer et al. 2017]</a>.</p>

<h4 id="graph-computation">Graph Computation</h4>

<p>So far, we have formally defined graphs and distinguished three types of attention-levels which define their output. Thereafter, we explain how exactly the computation of this output is conducted. The computational scheme within GNNs involves two main properties. First, it is based on <em>shared</em> neural networks which are used to compute the updated features of all the nodes and edges. Second, it uses <em>aggregation functions</em> that pool these features in order to produce the output. These two properties provide GNNs with good combinatorial generalization capabilities. In fact, not only it enables good transfer between different nodes and edges (based on the shared networks), but also it leverages permutation invariance (based on the aggregation scheme).</p>

<p>We denote the shared neural networks between the nodes by \(NN_{nodes}\), the shared neural networks between edges by \(NN_{edges}\), and the readout neural network that produces the global output of the GNN by \(NN_{readout}\). Besides, we focus on <em>graph-level output</em>. The full computational scheme is based on three steps: the <em>edge updates</em>, the <em>node updates</em> and the <em>graph readout</em>.</p>

<p><strong>The edge update step.</strong> The edge update step consists in using the input features involving each edge \(i \rightarrow j\) to compute its updated features, which we note \(e'_{ij}\). More precisely, we consider the global input feature \(u\), the input features of the source node \(v_i\) and the input features of the recipient node \(v_j\). We use the shared network \(NN_{edges}\) to compute the updated features of all the edges. Formally, the updated features \(e'_{ij}\) of the edge \(i \rightarrow j\) are computed as follows:</p>

\[e'_{ij}~=~NN_{edges}(v_i, v_j, e_{ij}, u).\]

<p><strong>The node update step.</strong> The node update step aims at computing the updated features of all the nodes. We note \(v'_{i}\) these updated features for node \(i\). To do so, the input features of the underlying node, the global features as well as the aggregation of the updated features of the incoming edges to \(i\) are considered. The incoming edges to \(i\) correspond to edges whose source nodes are necessarily in the neighborhood of \(i\), \(\mathcal{N}(i)\). The shared network \(NN_{nodes}\) is used in this computation. Formally, the updated features \(v'_{i}\) of the node \(i\) are obtained as follows:</p>

\[v'_{i}~=~NN_{nodes}(v_i, Agg_{i \in \mathcal{N}(i)}(e'_{ij}), u).\]

<p><strong>The graph readout step.</strong> The graph readout step computes the global output of the graph. This quantity is obtained by aggregating all the updated features of the nodes within the graph. It uses the readout neural network \(NN_{readout}\). Formally, the output \(o\) of the GNN is computed as follows:</p>

\[o~=~NN_{readout}(Agg_{i \in graph}(v'_{i})).\]

<p>The computational steps we described above can be used in some other order. For example, one can first perform the node update using the input features of edges, then perform the edge updates using the updated nodes features. This choice usually depends on the domain and task at hand. Besides, our descriptions above are categorized within the family of <em>convolutional GNNs</em> <a class="citation" href="#bruna2013spectral">[Bruna et al. 2013; Henaff et al. 2015; Defferrard et al. 2016; Kipf and Welling 2016; Levie et al. 2018; Gilmer et al. 2017; Akakzia and Sigaud 2022]</a>, which generalize the operation of convolution from grid data to graph data by pooling features of neighbors when updating each node. There exist other categories of GNNs, such as <em>graph auto-encoders</em> <a class="citation" href="#cao2016deep">[Cao et al. 2016; Wang et al. 2016; Kipf and Welling 2016; Pan et al. 2018; Li et al. 2018]</a>, <em>spatio-temporal GNNs</em> <a class="citation" href="#yu2017spatio">[Yu et al. 2017; Li et al. 2017; Seo et al. 2018; Guo et al. 2019]</a> and <em>recurrent GNNs</em> <a class="citation" href="#scarselli2005graph">[Scarselli et al. 2005; Gallicchio and Micheli 2010; Li et al. 2015; Dai et al. 2018]</a>. Finally, the aggregation module used to perform node-wise pooling can be either some predefined permutation-invariant function such as sum, max or mean, or a more sophisticated self-attention-based function that learns attention weights for each node <a class="citation" href="#velivckovic2017graph">[Veličković et al. 2017]</a>.</p>

<h3 id="overview-on-graph-neural-networks-in-rl">Overview on Graph Neural Networks in RL</h3>

<p>Recently, Graph Neural Networks have been widely used in Reinforcement Learning. In fact, they promote sample efficiency, especially in multi-object manipulation domains, where object invariance becomes crucial for generalization. In this paragraph, we introduce an overview over recent works in RL using GNNs. We divide the works in two categories: GNNs used for <em>model-based</em> RL and for <em>model-free</em> RL.</p>

<p><strong>Model-based Reinforcement Learning.</strong> The idea of using GNNs in model-based reinforcement learning settings mainly amounts to representing the perceived world of the artificial agents with graphs. Recent papers have been using GNNs to learn prediction models by construction graph representations using the bodies and joints of the agents <a class="citation" href="#wang2016learning">[Wang et al. 2016; Hamrick et al. 2017; Sanchez-Gonzalez et al. 2018]</a>. This approach is shown to be successful in prediction, system identification and planning. However, these approaches struggle when the structure of the components and joints of the agent are different. For example, they work better on the Swimmer environment than HalfCheetah, since the latter contains more joints corresponding to different components (back leg, front leg, head …). Other approaches use Interaction Networks <a class="citation" href="#battaglia2016interaction">[Battaglia et al. 2016]</a>, which are a particular type of GNNs to implement transition models of the environment which they later use for imagination-based optimization <a class="citation" href="#hamrick2017metacontrol">[Hamrick et al. 2017]</a> or planning from scratch <a class="citation" href="#wang2016learning">[Wang et al. 2016]</a></p>

<p><strong>Model-free Reinforcement Learning.</strong> GNNs are also used in model-free reinforcement learning to model the policy and / or the value function <a class="citation" href="#wang2018nervenet">[Wang et al. 2018; Zambaldi et al. 2018; Bapst et al. 2019; Li et al. 2019; Colas et al. 2020; Akakzia et al. 2021]</a>. On the one hand, like the model-based setting, some approaches use them to represent the agent’s body and joints as a graph where the different components interact with each other to produce an action <a class="citation" href="#wang2018nervenet">[Wang et al. 2018]</a>. On the other hand, other approaches use it to represent the world in term of separate entities and attempt to capture the relational features between them <a class="citation" href="#zambaldi2018relational">[Zambaldi et al. 2018; Bapst et al. 2019; Li et al. 2019; Colas et al. 2020; Akakzia et al. 2021]</a>.</p>

<h3 id="limitations">Limitations</h3>

<p>In spite of their generalization capacities provided by their permutation invariance, GNNs still show some limitations to solve some classes of problems such as discriminating between certain non-isomorphic graphs <a class="citation" href="#kondor2018generalization">[Kondor and Trivedi 2018]</a>. Moreover, notions like recursion, control flow and conditional iteration are not straightforward to represent with graphs, and might require some domain-specific tweaks (for example, in interpreting abstract syntax trees). In fact, symbolic  programs using probabilistic models are shown to work better on these classes of problems <a class="citation" href="#tenenbaum2011grow">[Tenenbaum et al. 2011; Goodman et al. 2014; Lake et al. 2015]</a>. But more importantly, a more pressing question is about the origin of the graph networks that most of the methods work on. In fact, most approaches that use GNNs use graphs with predefined entities corresponding to structured objects. Removing this assumption, it is still unclear how to convert sensory data into more structured graph-like representations. Some lines of active research are exploring these issues <a class="citation" href="#watters2017visual">[Watters et al. 2017; Van Steenkiste et al. 2018; Li et al. 2018; Kipf et al. 2018]</a>.</p>

<!--- References -->

<ol class="bibliography"><li><span id="winston1970learning"><span style="font-variant: small-caps">Winston, P.H.</span> 1970. Learning structural descriptions from examples. <i>None</i>.</span></li>
<li><span id="palmer1975visual"><span style="font-variant: small-caps">Palmer, S.E.</span> 1975. Visual perception and world knowledge: Notes on a model of sensory-cognitive interaction. <i>Explorations in cognition</i>, 279–307.</span></li>
<li><span id="navon1977forest"><span style="font-variant: small-caps">Navon, D.</span> 1977. Forest before trees: The precedence of global features in visual perception. <i>Cognitive psychology</i> <i>9</i>, 3, 353–383.</span></li>
<li><span id="markman1989categorization"><span style="font-variant: small-caps">Markman, E.M.</span> 1989. <i>Categorization and naming in children: Problems of induction</i>. mit Press.</span></li>
<li><span id="kemp2008discovery"><span style="font-variant: small-caps">Kemp, C. and Tenenbaum, J.B.</span> 2008. The discovery of structural form. <i>Proceedings of the National Academy of Sciences</i> <i>105</i>, 31, 10687–10692.</span></li>
<li><span id="tenenbaum2011grow"><span style="font-variant: small-caps">Tenenbaum, J.B., Kemp, C., Griffiths, T.L., and Goodman, N.D.</span> 2011. How to grow a mind: Statistics, structure, and abstraction. <i>Science</i> <i>331</i>, 6022, 1279–1285.</span></li>
<li><span id="battaglia2016interaction"><span style="font-variant: small-caps">Battaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., and others</span>. 2016. Interaction networks for learning about objects, relations and physics. <i>Advances in neural information processing systems</i> <i>29</i>.</span></li>
<li><span id="battaglia2018relational"><span style="font-variant: small-caps">Battaglia, P.W., Hamrick, J.B., Bapst, V., et al.</span> 2018. Relational inductive biases, deep learning, and graph networks. <i>arXiv preprint arXiv:1806.01261</i>.</span></li>
<li><span id="godfrey2021theory"><span style="font-variant: small-caps">Godfrey-Smith, P.</span> 2021. Theory and reality. In: <i>Theory and Reality</i>. University of Chicago Press.</span></li>
<li><span id="redmon2016you"><span style="font-variant: small-caps">Redmon, J., Divvala, S., Girshick, R., and Farhadi, A.</span> 2016. You only look once: Unified, real-time object detection. <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i>, 779–788.</span></li>
<li><span id="ren2015faster"><span style="font-variant: small-caps">Ren, S., He, K., Girshick, R., and Sun, J.</span> 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. <i>Advances in neural information processing systems</i> <i>28</i>.</span></li>
<li><span id="zhang2016deep"><span style="font-variant: small-caps">Zhang, W., Xu, L., Li, Z., Lu, Q., and Liu, Y.</span> 2016. A deep-intelligence framework for online video processing. <i>IEEE Software</i> <i>33</i>, 2, 44–51.</span></li>
<li><span id="hinton2012deep"><span style="font-variant: small-caps">Hinton, G., Deng, L., Yu, D., et al.</span> 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. <i>IEEE Signal processing magazine</i> <i>29</i>, 6, 82–97.</span></li>
<li><span id="luong2015effective"><span style="font-variant: small-caps">Luong, M.-T., Pham, H., and Manning, C.D.</span> 2015. Effective approaches to attention-based neural machine translation. <i>arXiv preprint arXiv:1508.04025</i>.</span></li>
<li><span id="wu2017sequence"><span style="font-variant: small-caps">Wu, S., Zhang, D., Yang, N., Li, M., and Zhou, M.</span> 2017. Sequence-to-dependency neural machine translation. <i>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, 698–707.</span></li>
<li><span id="wang2016learning"><span style="font-variant: small-caps">Wang, J.X., Kurth-Nelson, Z., Tirumala, D., et al.</span> 2016. Learning to reinforcement learn. <i>arXiv preprint arXiv:1611.05763</i>.</span></li>
<li><span id="santoro2017simple"><span style="font-variant: small-caps">Santoro, A., Raposo, D., Barrett, D.G., et al.</span> 2017. A simple neural network module for relational reasoning. <i>Advances in neural information processing systems</i> <i>30</i>.</span></li>
<li><span id="zaheer2017deep"><span style="font-variant: small-caps">Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., and Smola, A.J.</span> 2017. Deep sets. <i>Advances in neural information processing systems</i>, 3391–3401.</span></li>
<li><span id="hamrick2017metacontrol"><span style="font-variant: small-caps">Hamrick, J.B., Ballard, A.J., Pascanu, R., Vinyals, O., Heess, N., and Battaglia, P.W.</span> 2017. Metacontrol for adaptive imagination-based optimization. <i>arXiv preprint arXiv:1705.02670</i>.</span></li>
<li><span id="sanchez2018graph"><span style="font-variant: small-caps">Sanchez-Gonzalez, A., Heess, N., Springenberg, J.T., et al.</span> 2018. Graph networks as learnable physics engines for inference and control. <i>International Conference on Machine Learning</i>, PMLR, 4470–4479.</span></li>
<li><span id="zambaldi2018relational"><span style="font-variant: small-caps">Zambaldi, V., Raposo, D., Santoro, A., et al.</span> 2018. Relational deep reinforcement learning. <i>arXiv preprint arXiv:1806.01830</i>.</span></li>
<li><span id="wang2018nervenet"><span style="font-variant: small-caps">Wang, T., Liao, R., Ba, J., and Fidler, S.</span> 2018. NerveNet: Learning Structured Policy with Graph Neural Networks. <i>International Conference on Learning Representations</i>.</span></li>
<li><span id="bapst2019structured"><span style="font-variant: small-caps">Bapst, V., Sanchez-Gonzalez, A., Doersch, C., et al.</span> 2019. Structured agents for physical construction. <i>International Conference on Machine Learning</i>, PMLR, 464–474.</span></li>
<li><span id="li2019towards"><span style="font-variant: small-caps">Li, R., Jabri, A., Darrell, T., and Agrawal, P.</span> 2019. Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning. <i>ArXiv preprint</i> <i>abs/1912.11032</i>.</span></li>
<li><span id="colas2020language"><span style="font-variant: small-caps">Colas, C., Karch, T., Lair, N., et al.</span> 2020. Language as a Cognitive Tool to Imagine Goals in Curiosity Driven
Exploration. <i>Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual</i>.</span></li>
<li><span id="akakzia2021grounding"><span style="font-variant: small-caps">Akakzia, A., Colas, C., Oudeyer, P.-Y., Chetouani, M., and Sigaud, O.</span> 2021. Grounding Language to Autonomously-Acquired Skills via Goal Generation. <i>9th International Conference on Learning Representations, ICLR 2021,
Virtual Event, Austria, May 3-7, 2021</i>, OpenReview.net.</span></li>
<li><span id="akakzia2022learning"><span style="font-variant: small-caps">Akakzia, A. and Sigaud, O.</span> 2022. Learning Object-Centered Autotelic Behaviors with Graph Neural Networks. <i>arXiv preprint arXiv:2204.05141</i>.</span></li>
<li><span id="bronstein2017geometric"><span style="font-variant: small-caps">Bronstein, M.M., Bruna, J., LeCun, Y., Szlam, A., and Vandergheynst, P.</span> 2017. Geometric deep learning: going beyond euclidean data. <i>IEEE Signal Processing Magazine</i> <i>34</i>, 4, 18–42.</span></li>
<li><span id="hamilton2017representation"><span style="font-variant: small-caps">Hamilton, W.L., Ying, R., and Leskovec, J.</span> 2017. Representation learning on graphs: Methods and applications. <i>arXiv preprint arXiv:1709.05584</i>.</span></li>
<li><span id="lee2018graph"><span style="font-variant: small-caps">Lee, J.B., Rossi, R., and Kong, X.</span> 2018. Graph classification using structural attention. <i>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</i>, 1666–1674.</span></li>
<li><span id="wu2020comprehensive"><span style="font-variant: small-caps">Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., and Philip, S.Y.</span> 2020. A comprehensive survey on graph neural networks. <i>IEEE transactions on neural networks and learning systems</i> <i>32</i>, 1, 4–24.</span></li>
<li><span id="watters2017visual"><span style="font-variant: small-caps">Watters, N., Zoran, D., Weber, T., Battaglia, P., Pascanu, R., and Tacchetti, A.</span> 2017. Visual interaction networks: Learning a physics simulator from video. <i>Advances in neural information processing systems</i> <i>30</i>.</span></li>
<li><span id="van2018relational"><span style="font-variant: small-caps">Van Steenkiste, S., Chang, M., Greff, K., and Schmidhuber, J.</span> 2018. Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. <i>arXiv preprint arXiv:1802.10353</i>.</span></li>
<li><span id="li2018learning"><span style="font-variant: small-caps">Li, Y., Vinyals, O., Dyer, C., Pascanu, R., and Battaglia, P.</span> 2018. Learning deep generative models of graphs. <i>arXiv preprint arXiv:1803.03324</i>.</span></li>
<li><span id="kipf2018neural"><span style="font-variant: small-caps">Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R.</span> 2018. Neural relational inference for interacting systems. <i>International Conference on Machine Learning</i>, PMLR, 2688–2697.</span></li>
<li><span id="chang2016compositional"><span style="font-variant: small-caps">Chang, M.B., Ullman, T., Torralba, A., and Tenenbaum, J.B.</span> 2016. A compositional object-based approach to learning physical dynamics. <i>arXiv preprint arXiv:1612.00341</i>.</span></li>
<li><span id="hamrick2018relational"><span style="font-variant: small-caps">Hamrick, J.B., Allen, K.R., Bapst, V., et al.</span> 2018. Relational inductive bias for physical construction in humans and machines. <i>ArXiv preprint</i> <i>abs/1806.01203</i>.</span></li>
<li><span id="gilmer2017neural"><span style="font-variant: small-caps">Gilmer, J., Schoenholz, S.S., Riley, P.F., Vinyals, O., and Dahl, G.E.</span> 2017. Neural message passing for quantum chemistry. <i>arXiv preprint arXiv:1704.01212</i>.</span></li>
<li><span id="bruna2013spectral"><span style="font-variant: small-caps">Bruna, J., Zaremba, W., Szlam, A., and LeCun, Y.</span> 2013. Spectral networks and locally connected networks on graphs. <i>arXiv preprint arXiv:1312.6203</i>.</span></li>
<li><span id="henaff2015deep"><span style="font-variant: small-caps">Henaff, M., Bruna, J., and LeCun, Y.</span> 2015. Deep convolutional networks on graph-structured data. <i>arXiv preprint arXiv:1506.05163</i>.</span></li>
<li><span id="defferrard2016convolutional"><span style="font-variant: small-caps">Defferrard, M., Bresson, X., and Vandergheynst, P.</span> 2016. Convolutional neural networks on graphs with fast localized spectral filtering. <i>Advances in neural information processing systems</i> <i>29</i>.</span></li>
<li><span id="kipf2016semi"><span style="font-variant: small-caps">Kipf, T.N. and Welling, M.</span> 2016. Semi-supervised classification with graph convolutional networks. <i>arXiv preprint arXiv:1609.02907</i>.</span></li>
<li><span id="levie2018cayleynets"><span style="font-variant: small-caps">Levie, R., Monti, F., Bresson, X., and Bronstein, M.M.</span> 2018. Cayleynets: Graph convolutional neural networks with complex rational spectral filters. <i>IEEE Transactions on Signal Processing</i> <i>67</i>, 1, 97–109.</span></li>
<li><span id="cao2016deep"><span style="font-variant: small-caps">Cao, S., Lu, W., and Xu, Q.</span> 2016. Deep neural networks for learning graph representations. <i>Proceedings of the AAAI Conference on Artificial Intelligence</i>.</span></li>
<li><span id="wang2016structural"><span style="font-variant: small-caps">Wang, D., Cui, P., and Zhu, W.</span> 2016. Structural deep network embedding. <i>Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</i>, 1225–1234.</span></li>
<li><span id="kipf2016variational"><span style="font-variant: small-caps">Kipf, T.N. and Welling, M.</span> 2016. Variational graph auto-encoders. <i>arXiv preprint arXiv:1611.07308</i>.</span></li>
<li><span id="pan2018adversarially"><span style="font-variant: small-caps">Pan, S., Hu, R., Long, G., Jiang, J., Yao, L., and Zhang, C.</span> 2018. Adversarially regularized graph autoencoder for graph embedding. <i>arXiv preprint arXiv:1802.04407</i>.</span></li>
<li><span id="yu2017spatio"><span style="font-variant: small-caps">Yu, B., Yin, H., and Zhu, Z.</span> 2017. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. <i>arXiv preprint arXiv:1709.04875</i>.</span></li>
<li><span id="li2017diffusion"><span style="font-variant: small-caps">Li, Y., Yu, R., Shahabi, C., and Liu, Y.</span> 2017. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. <i>arXiv preprint arXiv:1707.01926</i>.</span></li>
<li><span id="seo2018structured"><span style="font-variant: small-caps">Seo, Y., Defferrard, M., Vandergheynst, P., and Bresson, X.</span> 2018. Structured sequence modeling with graph convolutional recurrent networks. <i>International conference on neural information processing</i>, Springer, 362–373.</span></li>
<li><span id="guo2019attention"><span style="font-variant: small-caps">Guo, S., Lin, Y., Feng, N., Song, C., and Wan, H.</span> 2019. Attention based spatial-temporal graph convolutional networks for traffic flow forecasting. <i>Proceedings of the AAAI conference on artificial intelligence</i>, 922–929.</span></li>
<li><span id="scarselli2005graph"><span style="font-variant: small-caps">Scarselli, F., Yong, S.L., Gori, M., Hagenbuchner, M., Tsoi, A.C., and Maggini, M.</span> 2005. Graph neural networks for ranking web pages. <i>The 2005 IEEE/WIC/ACM International Conference on Web Intelligence (WI’05)</i>, IEEE, 666–672.</span></li>
<li><span id="gallicchio2010graph"><span style="font-variant: small-caps">Gallicchio, C. and Micheli, A.</span> 2010. Graph echo state networks. <i>The 2010 international joint conference on neural networks (IJCNN)</i>, IEEE, 1–8.</span></li>
<li><span id="li2015gated"><span style="font-variant: small-caps">Li, Y., Tarlow, D., Brockschmidt, M., and Zemel, R.</span> 2015. Gated graph sequence neural networks. <i>arXiv preprint arXiv:1511.05493</i>.</span></li>
<li><span id="dai2018learning"><span style="font-variant: small-caps">Dai, H., Kozareva, Z., Dai, B., Smola, A., and Song, L.</span> 2018. Learning steady-states of iterative algorithms over graphs. <i>International conference on machine learning</i>, PMLR, 1106–1114.</span></li>
<li><span id="velivckovic2017graph"><span style="font-variant: small-caps">Veličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., and Bengio, Y.</span> 2017. Graph attention networks. <i>arXiv preprint arXiv:1710.10903</i>.</span></li>
<li><span id="kondor2018generalization"><span style="font-variant: small-caps">Kondor, R. and Trivedi, S.</span> 2018. On the generalization of equivariance and convolution in neural networks to the action of compact groups. <i>International Conference on Machine Learning</i>, PMLR, 2747–2755.</span></li>
<li><span id="goodman2014concepts"><span style="font-variant: small-caps">Goodman, N.D., Tenenbaum, J.B., and Gerstenberg, T.</span> 2014. <i>Concepts in a probabilistic language of thought</i>. Center for Brains, Minds and Machines (CBMM).</span></li>
<li><span id="lake2015human"><span style="font-variant: small-caps">Lake, B.M., Salakhutdinov, R., and Tenenbaum, J.B.</span> 2015. Human-level concept learning through probabilistic program induction. <i>Science</i> <i>350</i>, 6266, 1332–1338.</span></li></ol>

    </div><!-- .post-content -->
    <div class="post-share">
      <span>Share:</span>
      <a target="_blank"
        href="https://twitter.com/intent/tweet?text=When%20Graph%20Neural%20Networks%20Meet%20Reinforcement%20Learning&amp;url=http://localhost:4000/blog/graph-neural-networks" rel="noopener">Twitter</a>
      <a target="_blank"
        href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/blog/graph-neural-networks&amp;t=When%20Graph%20Neural%20Networks%20Meet%20Reinforcement%20Learning" rel="noopener">Facebook</a>
    </div><!-- .share-post -->
    <div class="author-box">
      
      <div class="author-avatar" style="background-image: url('images/author.png')"><span class="screen-reader-text">Ahmed Akakzia's Picture</span></div>
      
      <div class="author-details">
        <h2 class="author-title">About Ahmed Akakzia</h2>
        <div class="author-bio"><p>Ahmed is a final year PhD candidate, passionate about artificial intelligence</p>
</div>
        
        <span class="author-location">Paris, France</span>
        
        
      </div><!-- .author-details -->
    </div><!-- .author-box -->
  </article><!-- .post -->

  
    <div class="comments-area">
  <div class="comments-inner">
    <h2 class="comments-title">Comments</h2>
    <div id="disqus_thread"></div>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
        Disqus</a>.</noscript>
  </div><!-- .comments-inner -->
</div><!-- .comments-area -->

<script type="text/javascript">
  var disqus_shortname = 'justgoodthemes';
  var disqus_developer = 0;
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
  
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

</main><!-- .main-content -->
      <footer class="site-footer">
  <div class="offsite-links">
    
      
<a href="https://twitter.com/aakakzia" target="_blank" rel="noopener">
  <span class="fa-twitter" aria-hidden="true"></span>
  <span class="screen-reader-text">Twitter</span>
</a>

<a href="https://github.com/akakzia" target="_blank" rel="noopener">
  <span class="fa-github" aria-hidden="true"></span>
  <span class="screen-reader-text">GitHub</span>
</a>

<a href="https://www.linkedin.com/in/ahmed-akakzia/" target="_blank" rel="noopener">
  <span class="fa-linkedin" aria-hidden="true"></span>
  <span class="screen-reader-text">LinkedIn</span>
</a>

    
  </div><!-- .offsite-links -->
  <div class="footer-bottom">
    <div class="site-info">
      <p>© 2022 Ahmed Akakzia. Theme customized from <a href="https://www.justgoodthemes.com">JustGoodThemes</a>.</p>

    </div><!-- .site-info -->
    <a href="#page" id="back-to-top" class="back-to-top"><span class="screen-reader-text">Back to the top </span>&#8593;</a>
  </div><!-- .footer-bottom -->
</footer><!-- .site-footer -->

    </div><!-- .inner -->
  </div><!-- .site -->

  <!-- Scripts -->
  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>
  
  <script src="/blog/assets/js/plugins.js"></script>
  <script src="/blog/assets/js/custom.js"></script>

</body>
</html>